import streamlit as st
import google.generativeai as genai

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="Gemini Smart Hub", layout="wide")

# --- Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ---
st.markdown("""
<style>
    .stTextArea textarea {direction: rtl; font-size: 16px;}
    div[data-testid="stChatMessage"] {direction: rtl; text-align: right;}
</style>
""", unsafe_allow_html=True)

# --- Ø³Ø­Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ---
api_keys = [v for k, v in st.secrets.items() if k.startswith("KEY_")]
if not api_keys:
    st.error("âŒ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…ÙÙ‚ÙˆØ¯Ø©! ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¶Ø¹Ù‡Ø§ ÙÙŠ Secrets.")
    st.stop()

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„
genai.configure(api_key=api_keys[0])

# --- Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ (Auto-Detection) ---
with st.sidebar:
    st.header("ğŸ® Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ")
    
    # Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙØ¹Ù„ÙŠØ§Ù‹ Ù„Ø­Ø³Ø§Ø¨Ùƒ
    try:
        model_list = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                model_list.append(m.name)
        # ØªØ±ØªÙŠØ¨Ù‡Ø§ Ù„ÙŠØ¸Ù‡Ø± Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹
        model_list.sort(reverse=True)
    except:
        model_list = ["models/gemini-1.5-flash"] # Ø§Ø­ØªÙŠØ§Ø·ÙŠ ÙÙŠ Ø­Ø§Ù„ Ø§Ù„ÙØ´Ù„
    
    # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø© (Ù„Ù† ØªØ®ØªØ§Ø± Ø®Ø·Ø£ Ø¨Ø¹Ø¯ Ø§Ù„ÙŠÙˆÙ…)
    selected_model = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù†Ø´Ø·:", model_list)
    
    # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    temp = st.slider("Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹:", 0.0, 1.0, 0.7)
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ---
st.title(f"ğŸ¤– {selected_model.split('/')[-1]}")

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©
if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„
if prompt := st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ÙŠ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©..."):
    # Ø¹Ø±Ø¶ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    with st.chat_message("assistant"):
        with st.spinner('Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±...'):
            try:
                # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø®ØªØ§Ø±
                model = genai.GenerativeModel(selected_model)
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ØªÙ†Ø³ÙŠÙ‚ Ø¬ÙˆØ¬Ù„
                history = [{"role": m["role"].replace("assistant", "model"), "parts": [m["content"]]} 
                           for m in st.session_state.messages[:-1]]
                
                chat = model.start_chat(history=history)
                response = chat.send_message(prompt, generation_config={"temperature": temp})
                
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
            except Exception as e:
                st.error(f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
