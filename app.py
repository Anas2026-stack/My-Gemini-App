import streamlit as st
import google.generativeai as genai

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="Gemini Auto-Pilot", layout="wide")

# --- Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ---
st.markdown("""
<style>
    .stTextArea textarea {direction: rtl; font-size: 16px;}
    div[data-testid="stChatMessage"] {direction: rtl; text-align: right;}
</style>
""", unsafe_allow_html=True)

# --- 1. Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© (Auth) ---
api_keys = [v for k, v in st.secrets.items() if k.startswith("KEY_")]
if not api_keys:
    st.error("Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Secrets")
    st.stop()

genai.configure(api_key=api_keys[0])

# --- 2. Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ (Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒÙŠ) ---
with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")
    
    # Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø³Ø­Ø±ÙŠØ©: Ù†Ø³Ø£Ù„ Ø¬ÙˆØ¬Ù„ "Ù…Ø§Ø°Ø§ Ù„Ø¯ÙŠÙƒØŸ" Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„ØªØ®Ù…ÙŠÙ†
    available_models = []
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                available_models.append(m.name)
        available_models.sort(reverse=True) # Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹
    except Exception as e:
        st.error(f"ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¬ÙˆØ¬Ù„: {e}")
    
    if not available_models:
        st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…ÙØªØ§Ø­.")
        st.stop()
        
    # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø© ØªØ¹Ø±Ø¶ ÙÙ‚Ø· Ù…Ø§ Ù‡Ùˆ "Ù…ÙˆØ¬ÙˆØ¯ ÙˆØ­Ù‚ÙŠÙ‚ÙŠ"
    selected_model = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…ØªØ§Ø­:", available_models)
    
    st.success(f"ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€: {selected_model}")
    
    # Ø²Ø± Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¶Ø¨Ø·
    if st.button("Ø¨Ø¯Ø¡ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- 3. ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---
st.title("ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ (Ø¨Ø¯ÙˆÙ† Ø£Ø®Ø·Ø§Ø¡)")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø§Øª
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ù‡Ù†Ø§..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø®ØªØ§Ø± Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹
            model = genai.GenerativeModel(selected_model)
            
            # ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØªØ§Ø±ÙŠØ®
            history_data = [{"role": m["role"].replace("assistant", "model"), "parts": [m["content"]]} 
                           for m in st.session_state.messages[:-1]]
            
            chat = model.start_chat(history=history_data)
            response = chat.send_message(prompt)
            
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø±Ø¯: {e}")
